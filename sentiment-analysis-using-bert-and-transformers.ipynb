{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":742210,"sourceType":"datasetVersion","datasetId":17}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yosefibrahim/sentiment-analysis-using-bert-and-transformers?scriptVersionId=179614102\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T13:35:47.68863Z","iopub.execute_input":"2024-03-17T13:35:47.68903Z","iopub.status.idle":"2024-03-17T13:35:47.71202Z","shell.execute_reply.started":"2024-03-17T13:35:47.689003Z","shell.execute_reply":"2024-03-17T13:35:47.710972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-24T11:37:53.920648Z","iopub.execute_input":"2024-03-24T11:37:53.921537Z","iopub.status.idle":"2024-03-24T11:37:54.977689Z","shell.execute_reply.started":"2024-03-24T11:37:53.921498Z","shell.execute_reply":"2024-03-24T11:37:54.976082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q transformers\n!pip install datasets\n!pip install evaluate\n!pip install rouge-score\n!pip install py7zr","metadata":{"scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-24T11:38:22.678912Z","iopub.execute_input":"2024-03-24T11:38:22.679956Z","iopub.status.idle":"2024-03-24T11:39:42.941414Z","shell.execute_reply.started":"2024-03-24T11:38:22.679917Z","shell.execute_reply":"2024-03-24T11:39:42.940446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing Libraries\n\n# Data Handling\nimport pandas as pd\nimport numpy as np\nfrom datasets import Dataset, load_metric\nimport shutil\nfrom collections import defaultdict\n\n# Data Visualization\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.subplots as sp\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nimport plotly.io as pio\nfrom IPython.display import display\nfrom plotly.offline import init_notebook_mode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ninit_notebook_mode(connected=True)\n\n# Statistics & Mathematics\nimport scipy.stats as stats\nimport statsmodels.api as sm\nfrom wordcloud import WordCloud, STOPWORDS\nfrom scipy.stats import shapiro, skew, anderson, kstest, gaussian_kde,spearmanr\nimport math\n\n# Transformers\nimport tensorflow as tf\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import TFAutoModelForSequenceClassification\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\nfrom transformers import AutoTokenizer, AutoConfig\nfrom scipy.special import softmax\nfrom transformers import BartTokenizer, BartForConditionalGeneration      # BERT Tokenizer and architecture\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments         # These will help us to fine-tune our model\nfrom transformers import pipeline                                         # Pipeline\nfrom transformers import DataCollatorForSeq2Seq                           # DataCollator to batch the data \nimport torch                                                              # PyTorch\nimport evaluate                                                           # Hugging Face's library for model evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom torch import nn, optim\n\nimport time\nimport datetime\nimport gc\nimport random\nfrom nltk.corpus import stopwords\n\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\nimport transformers\nfrom transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup\n\n\n# Other NLP libraries\nfrom textblob import TextBlob                                             # This is going to help us fix spelling mistakes in texts\nfrom sklearn.feature_extraction.text import TfidfVectorizer               # This is going to helps identify the most common terms in the corpus\nimport re                                                                 # This library allows us to clean text data\nimport nltk                                                               # Natural Language Toolkit\nnltk.download('punkt') \n\n\n# Hiding warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:40:37.281176Z","iopub.execute_input":"2024-03-24T11:40:37.281531Z","iopub.status.idle":"2024-03-24T11:41:00.307646Z","shell.execute_reply.started":"2024-03-24T11:40:37.281502Z","shell.execute_reply":"2024-03-24T11:41:00.30677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:41:00.309368Z","iopub.execute_input":"2024-03-24T11:41:00.310417Z","iopub.status.idle":"2024-03-24T11:41:00.362087Z","shell.execute_reply.started":"2024-03-24T11:41:00.310383Z","shell.execute_reply":"2024-03-24T11:41:00.361183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df =pd.read_csv(r'../input/twitter-airline-sentiment/Tweets.csv')\n#df = df[['airline_sentiment','text']]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:44:48.806484Z","iopub.execute_input":"2024-03-24T11:44:48.807505Z","iopub.status.idle":"2024-03-24T11:44:48.902881Z","shell.execute_reply.started":"2024-03-24T11:44:48.80746Z","shell.execute_reply":"2024-03-24T11:44:48.901954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['airline_sentiment'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:44:51.710451Z","iopub.execute_input":"2024-03-24T11:44:51.711069Z","iopub.status.idle":"2024-03-24T11:44:51.721618Z","shell.execute_reply.started":"2024-03-24T11:44:51.711039Z","shell.execute_reply":"2024-03-24T11:44:51.720657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['airline'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:44:54.074579Z","iopub.execute_input":"2024-03-24T11:44:54.074991Z","iopub.status.idle":"2024-03-24T11:44:54.082104Z","shell.execute_reply.started":"2024-03-24T11:44:54.074961Z","shell.execute_reply":"2024-03-24T11:44:54.081199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:44:54.960255Z","iopub.execute_input":"2024-03-24T11:44:54.960582Z","iopub.status.idle":"2024-03-24T11:44:54.99281Z","shell.execute_reply.started":"2024-03-24T11:44:54.960558Z","shell.execute_reply":"2024-03-24T11:44:54.991872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:44:57.336026Z","iopub.execute_input":"2024-03-24T11:44:57.336631Z","iopub.status.idle":"2024-03-24T11:44:57.356893Z","shell.execute_reply.started":"2024-03-24T11:44:57.336603Z","shell.execute_reply":"2024-03-24T11:44:57.355866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"airlines=['@VirginAmerica', '@United', '@Southwest', '@Delta', '@USAirways',\n       '@American']","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:44:59.89195Z","iopub.execute_input":"2024-03-24T11:44:59.892585Z","iopub.status.idle":"2024-03-24T11:44:59.896516Z","shell.execute_reply.started":"2024-03-24T11:44:59.892557Z","shell.execute_reply":"2024-03-24T11:44:59.895601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(text):\n    new_text = []\n    for t in text.split(\" \"):\n        t = '@user' if (t.startswith('@') and len(t) > 1 and t not in airlines) else t\n        t = 'http' if t.startswith('http') else t\n        new_text.append(t)\n    return \" \".join(new_text)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:07.736165Z","iopub.execute_input":"2024-03-24T11:45:07.736522Z","iopub.status.idle":"2024-03-24T11:45:07.742141Z","shell.execute_reply.started":"2024-03-24T11:45:07.736492Z","shell.execute_reply":"2024-03-24T11:45:07.741232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columnsTodrob=[\"negativereason\",\"negativereason_confidence\",\"airline_sentiment_gold\",\"negativereason_gold\",\"tweet_coord\"\\\n              ,\"tweet_location\",\"user_timezone\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:13.880403Z","iopub.execute_input":"2024-03-24T11:45:13.881291Z","iopub.status.idle":"2024-03-24T11:45:13.885629Z","shell.execute_reply.started":"2024-03-24T11:45:13.881257Z","shell.execute_reply":"2024-03-24T11:45:13.884652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns=columnsTodrob)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:16.401983Z","iopub.execute_input":"2024-03-24T11:45:16.402341Z","iopub.status.idle":"2024-03-24T11:45:16.410178Z","shell.execute_reply.started":"2024-03-24T11:45:16.402314Z","shell.execute_reply":"2024-03-24T11:45:16.409315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:19.175512Z","iopub.execute_input":"2024-03-24T11:45:19.176228Z","iopub.status.idle":"2024-03-24T11:45:19.18899Z","shell.execute_reply.started":"2024-03-24T11:45:19.176194Z","shell.execute_reply":"2024-03-24T11:45:19.187994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text'].apply(lambda x:len(x.split(' '))).max()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:23.879656Z","iopub.execute_input":"2024-03-24T11:45:23.880076Z","iopub.status.idle":"2024-03-24T11:45:23.913437Z","shell.execute_reply.started":"2024-03-24T11:45:23.880045Z","shell.execute_reply":"2024-03-24T11:45:23.912543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(\n    df[\"airline_sentiment\"], \n    nbins=25,\n    title= \"airline sentiment\",\n    template=\"plotly_dark\",\n    labels={\"value\" :\"airline sentiment\"},\n    color=df[\"airline_sentiment\"]\n)\nfig.update_traces(\n    textfont = {\n        \"size\" : 20,\n        \"family\" :\"tahoma\",\n        \"color\": \"#fff\"\n    },\n    hovertemplate = \"airline sentiment: %{x}<br>Frequency: %{y}\",\n    marker=dict(line=dict(color='#000', width=0.1))\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:32.040673Z","iopub.execute_input":"2024-03-24T11:45:32.041304Z","iopub.status.idle":"2024-03-24T11:45:33.687855Z","shell.execute_reply.started":"2024-03-24T11:45:32.04127Z","shell.execute_reply":"2024-03-24T11:45:33.686957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(\n    df[\"airline\"], \n    nbins=25,\n    title= \"airline\",\n    template=\"plotly_dark\",\n    labels={\"value\" :\"airline\"},\n    color=df[\"airline\"]\n)\nfig.update_traces(\n    textfont = {\n        \"size\" : 20,\n        \"family\" :\"tahoma\",\n        \"color\": \"#fff\"\n    },\n    hovertemplate = \"airline: %{x}<br>Frequency: %{y}\",\n    marker=dict(line=dict(color='#000', width=0.1))\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:37.704514Z","iopub.execute_input":"2024-03-24T11:45:37.705576Z","iopub.status.idle":"2024-03-24T11:45:37.882762Z","shell.execute_reply.started":"2024-03-24T11:45:37.705542Z","shell.execute_reply":"2024-03-24T11:45:37.881627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"senline=df[['airline_sentiment', 'airline']].groupby(['airline_sentiment'], as_index=False).value_counts().sort_values(by='airline', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:43.19179Z","iopub.execute_input":"2024-03-24T11:45:43.192163Z","iopub.status.idle":"2024-03-24T11:45:43.213292Z","shell.execute_reply.started":"2024-03-24T11:45:43.192135Z","shell.execute_reply":"2024-03-24T11:45:43.212411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"senline.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:44.055328Z","iopub.execute_input":"2024-03-24T11:45:44.056047Z","iopub.status.idle":"2024-03-24T11:45:44.065381Z","shell.execute_reply.started":"2024-03-24T11:45:44.056014Z","shell.execute_reply":"2024-03-24T11:45:44.06435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_tags(text):\n    text=preprocess(text)\n    clean = re.compile('<.*?>') # Compiling tags\n    clean = re.sub(clean, '', text) # Replacing tags text by an empty string\n    \n    # Removing empty dialogues\n    clean = '\\n'.join([line for line in clean.split('\\n') if not re.match('.*:\\s*$', line)])\n\n    return clean","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:46.343563Z","iopub.execute_input":"2024-03-24T11:45:46.344051Z","iopub.status.idle":"2024-03-24T11:45:46.349511Z","shell.execute_reply.started":"2024-03-24T11:45:46.344014Z","shell.execute_reply":"2024-03-24T11:45:46.348444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(data_frame = senline,\n             x = senline['airline'],\n             y = senline['count'],\n             color = senline['airline_sentiment'],\n             title = \"airline sentiment and airline\",\n             #color_discrete_sequence=[\"#45FFCA\", \"#D09CFA\", \"#FF9B9B\"],\n             labels= {\"index\" :\"sentiment\", \"y\": \"airline in PCT(%)\"},\n             template=\"plotly_dark\",\n             text = senline['airline_sentiment']\n            )\n\n\nfig.update_traces(\n    textfont = {\n        \"size\" : 16,\n        \"family\" :\"arial\",\n        \"color\": \"#222\"\n    },\n    hovertemplate = \"sentiment: %{x}<br>airline: %{y}\",\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:49.654508Z","iopub.execute_input":"2024-03-24T11:45:49.654995Z","iopub.status.idle":"2024-03-24T11:45:49.762407Z","shell.execute_reply.started":"2024-03-24T11:45:49.654963Z","shell.execute_reply":"2024-03-24T11:45:49.761497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df = df[df['airline_sentiment']!='neutral']","metadata":{"execution":{"iopub.status.busy":"2024-03-17T14:10:12.25452Z","iopub.execute_input":"2024-03-17T14:10:12.254843Z","iopub.status.idle":"2024-03-17T14:10:12.258849Z","shell.execute_reply.started":"2024-03-17T14:10:12.254817Z","shell.execute_reply":"2024-03-17T14:10:12.257946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"senline=df[['airline_sentiment', 'airline']].groupby(['airline_sentiment'], as_index=False).value_counts().sort_values(by='airline', ascending=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:52.924558Z","iopub.execute_input":"2024-03-24T11:45:52.924929Z","iopub.status.idle":"2024-03-24T11:45:52.941927Z","shell.execute_reply.started":"2024-03-24T11:45:52.924899Z","shell.execute_reply":"2024-03-24T11:45:52.941199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(data_frame = senline,\n             x = senline['airline'],\n             y = senline['count'],\n             color = senline['airline_sentiment'],\n             title = \"airline sentiment and airline\",\n             #color_discrete_sequence=[\"#45FFCA\", \"#D09CFA\", \"#FF9B9B\"],\n             labels= {\"index\" :\"sentiment\", \"y\": \"airline in PCT(%)\"},\n             template=\"plotly_dark\",\n             text = senline['airline_sentiment']\n            )\n\n\nfig.update_traces(\n    textfont = {\n        \"size\" : 16,\n        \"family\" :\"arial\",\n        \"color\": \"#222\"\n    },\n    hovertemplate = \"sentiment: %{x}<br>airline: %{y}\",\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:54.89556Z","iopub.execute_input":"2024-03-24T11:45:54.896502Z","iopub.status.idle":"2024-03-24T11:45:54.977652Z","shell.execute_reply.started":"2024-03-24T11:45:54.896472Z","shell.execute_reply":"2024-03-24T11:45:54.976671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_wordcloud(text,Title):\n    all_text = \" \".join(text)\n    wordcloud = WordCloud(width=800, \n                          height=400,\n                          stopwords=set(STOPWORDS), \n                          background_color='black').generate(all_text)\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.title(Title)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:57.147533Z","iopub.execute_input":"2024-03-24T11:45:57.148153Z","iopub.status.idle":"2024-03-24T11:45:57.154258Z","shell.execute_reply.started":"2024-03-24T11:45:57.148121Z","shell.execute_reply":"2024-03-24T11:45:57.153095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''sent={\"negative\":0,\n     \"positive\":1}'''\nsent={\"negative\":0,\n     \"positive\":2,\n     \"neutral\":1}\ndf['airline_sentiment_encodded']=df[\"airline_sentiment\"].map(sent)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:45:59.266493Z","iopub.execute_input":"2024-03-24T11:45:59.266973Z","iopub.status.idle":"2024-03-24T11:45:59.274955Z","shell.execute_reply.started":"2024-03-24T11:45:59.26694Z","shell.execute_reply":"2024-03-24T11:45:59.273886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"cleaned_text\"]=df[\"text\"].apply(clean_tags)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:46:01.905047Z","iopub.execute_input":"2024-03-24T11:46:01.90562Z","iopub.status.idle":"2024-03-24T11:46:02.140428Z","shell.execute_reply.started":"2024-03-24T11:46:01.905581Z","shell.execute_reply":"2024-03-24T11:46:02.139477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive = df[df['airline_sentiment_encodded']==1]['cleaned_text'].tolist()\ngenerate_wordcloud(positive,'Positive Review')","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:46:04.475761Z","iopub.execute_input":"2024-03-24T11:46:04.476471Z","iopub.status.idle":"2024-03-24T11:46:05.666486Z","shell.execute_reply.started":"2024-03-24T11:46:04.47644Z","shell.execute_reply":"2024-03-24T11:46:05.665587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative = df[df['airline_sentiment_encodded']==0]['cleaned_text'].tolist()\ngenerate_wordcloud(negative,'negative Review')","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:46:09.462917Z","iopub.execute_input":"2024-03-24T11:46:09.463267Z","iopub.status.idle":"2024-03-24T11:46:11.186349Z","shell.execute_reply.started":"2024-03-24T11:46:09.463241Z","shell.execute_reply":"2024-03-24T11:46:11.185424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"natural = df[df['airline_sentiment_encodded']==2]['cleaned_text'].tolist()\ngenerate_wordcloud(natural,'natural Review')","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:47:07.501616Z","iopub.execute_input":"2024-03-24T11:47:07.502457Z","iopub.status.idle":"2024-03-24T11:47:08.556956Z","shell.execute_reply.started":"2024-03-24T11:47:07.502426Z","shell.execute_reply":"2024-03-24T11:47:08.556073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test1 = clean_tags(df['text'].iloc[50]) # Applying function to example text\n\n# Printing results\nprint(test1)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:47:24.960384Z","iopub.execute_input":"2024-03-24T11:47:24.960989Z","iopub.status.idle":"2024-03-24T11:47:24.966189Z","shell.execute_reply.started":"2024-03-24T11:47:24.960957Z","shell.execute_reply":"2024-03-24T11:47:24.965251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.airline_sentiment_encodded.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:47:42.453355Z","iopub.execute_input":"2024-03-24T11:47:42.453946Z","iopub.status.idle":"2024-03-24T11:47:42.46325Z","shell.execute_reply.started":"2024-03-24T11:47:42.453915Z","shell.execute_reply":"2024-03-24T11:47:42.462076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=df[[\"cleaned_text\",\"airline_sentiment_encodded\"]].reset_index()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:47:44.830356Z","iopub.execute_input":"2024-03-24T11:47:44.830707Z","iopub.status.idle":"2024-03-24T11:47:44.838073Z","shell.execute_reply.started":"2024-03-24T11:47:44.83068Z","shell.execute_reply":"2024-03-24T11:47:44.837094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:49:35.852344Z","iopub.execute_input":"2024-03-24T11:49:35.853269Z","iopub.status.idle":"2024-03-24T11:49:35.862743Z","shell.execute_reply.started":"2024-03-24T11:49:35.853235Z","shell.execute_reply":"2024-03-24T11:49:35.861839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=df1[\"cleaned_text\"]\ny=df1[\"airline_sentiment_encodded\"]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:49:30.151984Z","iopub.execute_input":"2024-03-24T11:49:30.152712Z","iopub.status.idle":"2024-03-24T11:49:30.156934Z","shell.execute_reply.started":"2024-03-24T11:49:30.152684Z","shell.execute_reply":"2024-03-24T11:49:30.155863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:49:30.793284Z","iopub.execute_input":"2024-03-24T11:49:30.793642Z","iopub.status.idle":"2024-03-24T11:49:30.800581Z","shell.execute_reply.started":"2024-03-24T11:49:30.793614Z","shell.execute_reply":"2024-03-24T11:49:30.799662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sw = stopwords.words('english')\n\ndef clean_text(text):\n    \n    text = text.lower()\n    \n    text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n\n    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n    #text = re.sub(r\"http\", \"\",text)\n    \n    html=re.compile(r'<.*?>') \n    \n    text = html.sub(r'',text) #Removing html tags\n    \n    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n    for p in punctuations:\n        text = text.replace(p,'') #Removing punctuations\n        \n    text = [word.lower() for word in text.split() if word.lower() not in sw]\n    \n    text = \" \".join(text) #removing stopwords\n    \n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    text = emoji_pattern.sub(r'', text) #Removing emojis\n    \n    return text","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:50:08.450293Z","iopub.execute_input":"2024-03-24T11:50:08.450684Z","iopub.status.idle":"2024-03-24T11:50:08.464517Z","shell.execute_reply.started":"2024-03-24T11:50:08.450656Z","shell.execute_reply":"2024-03-24T11:50:08.463643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['cleaned_text'] = df1['cleaned_text'].apply(lambda x: clean_text(x))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T11:51:23.14965Z","iopub.execute_input":"2024-03-24T11:51:23.15052Z","iopub.status.idle":"2024-03-24T11:51:24.031924Z","shell.execute_reply.started":"2024-03-24T11:51:23.150489Z","shell.execute_reply":"2024-03-24T11:51:24.031005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df,test_df= train_test_split(df1, test_size=0.1, random_state=90,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:22:39.756232Z","iopub.execute_input":"2024-03-24T12:22:39.756943Z","iopub.status.idle":"2024-03-24T12:22:39.764321Z","shell.execute_reply.started":"2024-03-24T12:22:39.756911Z","shell.execute_reply":"2024-03-24T12:22:39.763558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tweets = train_df.cleaned_text.values\nlabels = train_df['airline_sentiment_encodded'].values","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:23:13.108475Z","iopub.execute_input":"2024-03-24T12:23:13.108823Z","iopub.status.idle":"2024-03-24T12:23:13.113692Z","shell.execute_reply.started":"2024-03-24T12:23:13.108797Z","shell.execute_reply":"2024-03-24T12:23:13.11269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:23:14.037513Z","iopub.execute_input":"2024-03-24T12:23:14.03823Z","iopub.status.idle":"2024-03-24T12:23:14.233754Z","shell.execute_reply.started":"2024-03-24T12:23:14.038199Z","shell.execute_reply":"2024-03-24T12:23:14.232985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(' Original: ', tweets[5])\nprint()\n# Print the sentence split into tokens.\nprint('Tokenized: ', tokenizer.tokenize(tweets[5]))\nprint()\n# Print the sentence mapped to token ids.\nprint('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[5])))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:23:14.862184Z","iopub.execute_input":"2024-03-24T12:23:14.862562Z","iopub.status.idle":"2024-03-24T12:23:14.869887Z","shell.execute_reply.started":"2024-03-24T12:23:14.862533Z","shell.execute_reply":"2024-03-24T12:23:14.868957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = 0\n\n# For every sentence...\nfor sent in tweets:\n\n    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n\n    # Update the maximum sentence length.\n    max_len = max(max_len, len(input_ids))\n\nprint('Max sentence length: ', max_len)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:23:15.815196Z","iopub.execute_input":"2024-03-24T12:23:15.81592Z","iopub.status.idle":"2024-03-24T12:23:22.613474Z","shell.execute_reply.started":"2024-03-24T12:23:15.815888Z","shell.execute_reply":"2024-03-24T12:23:22.612482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = []\nattention_masks = []\n\n# For every tweet...\nfor tweet in tweets:\n    # `encode_plus` will:\n    #   (1) Tokenize the sentence.\n    #   (2) Prepend the `[CLS]` token to the start.\n    #   (3) Append the `[SEP]` token to the end.\n    #   (4) Map tokens to their IDs.\n    #   (5) Pad or truncate the sentence to `max_length`\n    #   (6) Create attention masks for [PAD] tokens.\n    encoded_dict = tokenizer.encode_plus(\n                        tweet,                      # Sentence to encode.\n                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n                        max_length = max_len,           # Pad & truncate all sentences.\n                        pad_to_max_length = True,\n                        return_attention_mask = True,   # Construct attn. masks.\n                        return_tensors = 'pt',     # Return pytorch tensors.\n                   )\n    \n    # Add the encoded sentence to the list.    \n    input_ids.append(encoded_dict['input_ids'])\n    \n    # And its attention mask (simply differentiates padding from non-padding).\n    attention_masks.append(encoded_dict['attention_mask'])\n\n# Convert the lists into tensors.\ninput_ids = torch.cat(input_ids, dim=0)\nattention_masks = torch.cat(attention_masks, dim=0)\nlabels = torch.tensor(labels)\n\n# Print sentence 0, now as a list of IDs.\nprint('Original: ', tweets[0])\nprint('Token IDs:', input_ids[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:23:25.390562Z","iopub.execute_input":"2024-03-24T12:23:25.391267Z","iopub.status.idle":"2024-03-24T12:23:33.730992Z","shell.execute_reply.started":"2024-03-24T12:23:25.391234Z","shell.execute_reply":"2024-03-24T12:23:33.729997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Calculate the number of samples to include in each set.\n# train_size = int(0.8 * len(dataset))\n# val_size = int(0.15 * len(dataset))\n# # val_size = len(dataset)  - train_size\n# # val_size = val_size  - train_size\n# test_size = int(0.05 * len(dataset))\n# val_size,train_size,test_size,len(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:09:32.949484Z","iopub.execute_input":"2024-03-24T12:09:32.950328Z","iopub.status.idle":"2024-03-24T12:09:32.957111Z","shell.execute_reply.started":"2024-03-24T12:09:32.950289Z","shell.execute_reply":"2024-03-24T12:09:32.956171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine the training inputs into a TensorDataset.\ndataset = TensorDataset(input_ids, attention_masks, labels)\n\n# Create a 90-10 train-validation split.\n\n# Calculate the number of samples to include in each set.\ntrain_size = int(0.8 * len(dataset))\n# val_size = int(0.2 * len(dataset))\nval_size = len(dataset)  - train_size\n# test_size = int(0.05 * len(dataset))\n\n# Divide the dataset by randomly selecting samples.\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n# val_size = int(0.7 * len(val_dataset))\n# test_size = len(val_dataset)  - val_size\n# val_dataset, test_dataset= random_split(val_dataset, [val_size, test_size])\n\nprint('{:>5,} training samples'.format(train_size))\nprint('{:>5,} validation samples'.format(val_size))\n# print('{:>5,} test samples'.format(test_size))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:24:57.113012Z","iopub.execute_input":"2024-03-24T12:24:57.113677Z","iopub.status.idle":"2024-03-24T12:24:57.120605Z","shell.execute_reply.started":"2024-03-24T12:24:57.113645Z","shell.execute_reply":"2024-03-24T12:24:57.119673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The DataLoader needs to know our batch size for training, so we specify it \n# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n# size of 16 or 32.\nbatch_size = 32\n\n# Create the DataLoaders for our training and validation sets.\n# We'll take training samples in random order. \ntrain_dataloader = DataLoader(\n            train_dataset,  # The training samples.\n            sampler = RandomSampler(train_dataset), # Select batches randomly\n            batch_size = batch_size # Trains with this batch size.\n        )\n\n# For validation the order doesn't matter, so we'll just read them sequentially.\nvalidation_dataloader = DataLoader(\n            val_dataset, # The validation samples.\n            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:25:37.185155Z","iopub.execute_input":"2024-03-24T12:25:37.185515Z","iopub.status.idle":"2024-03-24T12:25:37.191003Z","shell.execute_reply.started":"2024-03-24T12:25:37.185487Z","shell.execute_reply":"2024-03-24T12:25:37.190099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load BertForSequenceClassification, the pretrained BERT model with a single \n# linear classification layer on top. \nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n    num_labels = 3, # The number of output labels--2 for binary classification.\n                    # You can increase this for multi-class tasks.   \n    output_attentions = False, # Whether the model returns attentions weights.\n    output_hidden_states = False, # Whether the model returns all hidden-states.\n)\n\n# if device == \"cuda:0\":\n# # Tell pytorch to run this model on the GPU.\n#     model = model.cuda()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:25:40.750127Z","iopub.execute_input":"2024-03-24T12:25:40.75049Z","iopub.status.idle":"2024-03-24T12:25:41.308562Z","shell.execute_reply.started":"2024-03-24T12:25:40.750462Z","shell.execute_reply":"2024-03-24T12:25:41.307754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(),\n                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n                )","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:25:43.559401Z","iopub.execute_input":"2024-03-24T12:25:43.559769Z","iopub.status.idle":"2024-03-24T12:25:43.567943Z","shell.execute_reply.started":"2024-03-24T12:25:43.559741Z","shell.execute_reply":"2024-03-24T12:25:43.567126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of training epochs. The BERT authors recommend between 2 and 4. \n# We chose to run for 4, but we'll see later that this may be over-fitting the\n# training data.\nepochs = 4\n\n# Total number of training steps is [number of batches] x [number of epochs]. \n# (Note that this is not the same as the number of training samples).\ntotal_steps = len(train_dataloader) * epochs\n\n# Create the learning rate scheduler.\nscheduler = get_linear_schedule_with_warmup(optimizer, \n                                            num_warmup_steps = 0, # Default value in run_glue.py\n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:25:45.973858Z","iopub.execute_input":"2024-03-24T12:25:45.97421Z","iopub.status.idle":"2024-03-24T12:25:45.97971Z","shell.execute_reply.started":"2024-03-24T12:25:45.974184Z","shell.execute_reply":"2024-03-24T12:25:45.978614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:25:50.041182Z","iopub.execute_input":"2024-03-24T12:25:50.041592Z","iopub.status.idle":"2024-03-24T12:25:50.047051Z","shell.execute_reply.started":"2024-03-24T12:25:50.041562Z","shell.execute_reply":"2024-03-24T12:25:50.046116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:25:50.976537Z","iopub.execute_input":"2024-03-24T12:25:50.977134Z","iopub.status.idle":"2024-03-24T12:25:50.983216Z","shell.execute_reply.started":"2024-03-24T12:25:50.977083Z","shell.execute_reply":"2024-03-24T12:25:50.982253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_val = 42\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\ntraining_stats = []\n\n# Measure the total training time for the whole run.\ntotal_t0 = time.time()\n\n# For each epoch...\nfor epoch_i in range(0, epochs):\n    \n    # ========================================\n    #               Training\n    # ========================================\n    # Perform one full pass over the training set.\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n    # Measure how long the training epoch takes.\n    t0 = time.time()\n    total_train_loss = 0\n    model.train()\n    for step, batch in enumerate(train_dataloader):\n        # Unpack this training batch from our dataloader. \n        #\n        # As we unpack the batch, we'll also copy each tensor to the device using the \n        # `to` method.\n        #\n        # `batch` contains three pytorch tensors:\n        #   [0]: input ids \n        #   [1]: attention masks\n        #   [2]: labels \n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        optimizer.zero_grad()\n        output = model(b_input_ids, \n                             token_type_ids=None, \n                             attention_mask=b_input_mask, \n                             labels=b_labels)        \n        loss = output.loss\n        total_train_loss += loss.item()\n        # Perform a backward pass to calculate the gradients.\n        loss.backward()\n        # Clip the norm of the gradients to 1.0.\n        # This is to help prevent the \"exploding gradients\" problem.\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        # Update parameters and take a step using the computed gradient.\n        # The optimizer dictates the \"update rule\"--how the parameters are\n        # modified based on their gradients, the learning rate, etc.\n        optimizer.step()\n        # Update the learning rate.\n        scheduler.step()\n\n    # Calculate the average loss over all of the batches.\n    avg_train_loss = total_train_loss / len(train_dataloader)            \n    \n    # Measure how long this epoch took.\n    training_time = format_time(time.time() - t0)\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epcoh took: {:}\".format(training_time))\n    # ========================================\n    #               Validation\n    # ========================================\n    # After the completion of each training epoch, measure our performance on\n    # our validation set.\n    print(\"\")\n    print(\"Running Validation...\")\n    t0 = time.time()\n    # Put the model in evaluation mode--the dropout layers behave differently\n    # during evaluation.\n    model.eval()\n    # Tracking variables \n    total_eval_accuracy = 0\n    best_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n    # Evaluate data for one epoch\n    for batch in validation_dataloader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        # Tell pytorch not to bother with constructing the compute graph during\n        # the forward pass, since this is only needed for backprop (training).\n        with torch.no_grad():        \n            output= model(b_input_ids, \n                                   token_type_ids=None, \n                                   attention_mask=b_input_mask,\n                                   labels=b_labels)\n        loss = output.loss\n        total_eval_loss += loss.item()\n        # Move logits and labels to CPU if we are using GPU\n        logits = output.logits\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        # Calculate the accuracy for this batch of test sentences, and\n        # accumulate it over all batches.\n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n    # Report the final accuracy for this validation run.\n    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n    # Calculate the average loss over all of the batches.\n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    # Measure how long the validation run took.\n    validation_time = format_time(time.time() - t0)\n    if avg_val_accuracy > best_eval_accuracy:\n        torch.save(model, 'bert_model')\n        best_eval_accuracy = avg_val_accuracy\n    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    #print(\"  Validation took: {:}\".format(validation_time))\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\nprint(\"\")\nprint(\"Training complete!\")\n\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:25:53.208128Z","iopub.execute_input":"2024-03-24T12:25:53.20848Z","iopub.status.idle":"2024-03-24T12:31:36.181949Z","shell.execute_reply.started":"2024-03-24T12:25:53.208454Z","shell.execute_reply":"2024-03-24T12:31:36.181063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('bert_model')","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:32:17.410985Z","iopub.execute_input":"2024-03-24T12:32:17.411604Z","iopub.status.idle":"2024-03-24T12:32:17.763258Z","shell.execute_reply.started":"2024-03-24T12:32:17.411575Z","shell.execute_reply":"2024-03-24T12:32:17.762431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_tweets = test_df['cleaned_text'].values","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:32:42.103595Z","iopub.execute_input":"2024-03-24T12:32:42.104506Z","iopub.status.idle":"2024-03-24T12:32:42.111335Z","shell.execute_reply.started":"2024-03-24T12:32:42.104471Z","shell.execute_reply":"2024-03-24T12:32:42.108945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input_ids = []\ntest_attention_masks = []\nfor tweet in test_tweets:\n    encoded_dict = tokenizer.encode_plus(\n                        tweet,                     \n                        add_special_tokens = True, \n                        max_length = max_len,           \n                        pad_to_max_length = True,\n                        return_attention_mask = True,\n                        return_tensors = 'pt',\n                   )\n    test_input_ids.append(encoded_dict['input_ids'])\n    test_attention_masks.append(encoded_dict['attention_mask'])\ntest_input_ids = torch.cat(test_input_ids, dim=0)\ntest_attention_masks = torch.cat(test_attention_masks, dim=0)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:32:46.837168Z","iopub.execute_input":"2024-03-24T12:32:46.837894Z","iopub.status.idle":"2024-03-24T12:32:47.784826Z","shell.execute_reply.started":"2024-03-24T12:32:46.837866Z","shell.execute_reply":"2024-03-24T12:32:47.783853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TensorDataset(test_input_ids, test_attention_masks)\ntest_dataloader = DataLoader(\n            test_dataset, # The validation samples.\n            sampler = SequentialSampler(test_dataset), # Pull out batches sequentially.\n            batch_size = batch_size # Evaluate with this batch size.\n        )","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:32:48.740348Z","iopub.execute_input":"2024-03-24T12:32:48.740715Z","iopub.status.idle":"2024-03-24T12:32:48.745711Z","shell.execute_reply.started":"2024-03-24T12:32:48.740688Z","shell.execute_reply":"2024-03-24T12:32:48.74478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor batch in test_dataloader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        with torch.no_grad():        \n            output= model(b_input_ids, \n                                   token_type_ids=None, \n                                   attention_mask=b_input_mask)\n            logits = output.logits\n            logits = logits.detach().cpu().numpy()\n            pred_flat = np.argmax(logits, axis=1).flatten()\n            \n            predictions.extend(list(pred_flat))","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:32:51.350923Z","iopub.execute_input":"2024-03-24T12:32:51.351977Z","iopub.status.idle":"2024-03-24T12:32:54.716827Z","shell.execute_reply.started":"2024-03-24T12:32:51.351944Z","shell.execute_reply":"2024-03-24T12:32:54.715841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_output = pd.DataFrame()\n#df_output['id'] = df_test['id']\ndf_output['target'] =predictions\ndf_output.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:32:58.054051Z","iopub.execute_input":"2024-03-24T12:32:58.054895Z","iopub.status.idle":"2024-03-24T12:32:58.074344Z","shell.execute_reply.started":"2024-03-24T12:32:58.054862Z","shell.execute_reply":"2024-03-24T12:32:58.073471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_output.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:33:00.417047Z","iopub.execute_input":"2024-03-24T12:33:00.417437Z","iopub.status.idle":"2024-03-24T12:33:00.426645Z","shell.execute_reply.started":"2024-03-24T12:33:00.417406Z","shell.execute_reply":"2024-03-24T12:33:00.425532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.cleaned_text[13176]","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:33:42.113675Z","iopub.execute_input":"2024-03-24T12:33:42.11405Z","iopub.status.idle":"2024-03-24T12:33:42.123838Z","shell.execute_reply.started":"2024-03-24T12:33:42.114022Z","shell.execute_reply":"2024-03-24T12:33:42.122357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text='user second flight put cancelled flightled explanation missed first meeting outraged'","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:34:00.556469Z","iopub.execute_input":"2024-03-24T12:34:00.556886Z","iopub.status.idle":"2024-03-24T12:34:00.561132Z","shell.execute_reply.started":"2024-03-24T12:34:00.556856Z","shell.execute_reply":"2024-03-24T12:34:00.560058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def product(text):\n    text=clean_text(text)\n    encoded_dict = tokenizer.encode_plus(\n                        text,                     \n                        add_special_tokens = True, \n                        max_length = max_len,           \n                        pad_to_max_length = True,\n                        return_attention_mask = True,\n                        return_tensors = 'pt',\n                   )\n    test_input_ids=[encoded_dict['input_ids']]\n    test_attention_masks=[encoded_dict['attention_mask']]\n    test_input_ids = torch.cat(test_input_ids, dim=0).to(device)\n    test_attention_masks = torch.cat(test_attention_masks, dim=0).to(device)\n    with torch.no_grad():        \n        output= model(test_input_ids, \n                               token_type_ids=None, \n                               attention_mask=test_attention_masks)\n        logits = output.logits\n        logits = logits.detach().cpu().numpy()\n        pred_flat = np.argmax(logits, axis=1).flatten()\n    if pred_flat==0:\n        print(\"negative\")\n    elif pred_flat==2:\n        print(\"Positive\")\n    else:\n        print(\"Natural\")","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:34:01.760335Z","iopub.execute_input":"2024-03-24T12:34:01.761195Z","iopub.status.idle":"2024-03-24T12:34:01.769146Z","shell.execute_reply.started":"2024-03-24T12:34:01.761161Z","shell.execute_reply":"2024-03-24T12:34:01.768056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"product(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:34:24.742025Z","iopub.execute_input":"2024-03-24T12:34:24.742765Z","iopub.status.idle":"2024-03-24T12:34:24.762675Z","shell.execute_reply.started":"2024-03-24T12:34:24.742713Z","shell.execute_reply":"2024-03-24T12:34:24.761792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text='last summer appointment get new tires wait super long time also went week\\\nfix minor problem tire put fixed free, next morning issue called complain, manager\\\neven apologize frustrated never going back seem overpriced,'","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:35:22.519396Z","iopub.execute_input":"2024-03-24T12:35:22.519774Z","iopub.status.idle":"2024-03-24T12:35:22.524358Z","shell.execute_reply.started":"2024-03-24T12:35:22.519745Z","shell.execute_reply":"2024-03-24T12:35:22.523369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"product(text)","metadata":{"execution":{"iopub.status.busy":"2024-03-24T12:35:29.020588Z","iopub.execute_input":"2024-03-24T12:35:29.021044Z","iopub.status.idle":"2024-03-24T12:35:29.046905Z","shell.execute_reply.started":"2024-03-24T12:35:29.021008Z","shell.execute_reply":"2024-03-24T12:35:29.045662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}